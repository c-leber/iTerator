{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iTerator\n",
    "## Modular workflow for improved short-read assemblies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting paths\n",
    "Set paths in relation to the directory that the notebook is running in.\n",
    "\n",
    "Paths must be set for SPAdes, QUAST, bbmap, SSPACE/Gapfiller, and Multi-CSAR\n",
    "\n",
    "(SSPACE and GapFiller directories should be combined)\n",
    "\n",
    "Paths must also be set for the directories containg reads and references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAdes_dir = './SPAdes-3.14.0-Linux'\n",
    "quast_dir = './quast-5.0.2'\n",
    "bbmap_dir = './bbmap'\n",
    "SSPACE_GF_dir = './SSPACE_and_GapFiller'\n",
    "MultiCSAR_dir =  './Multi-CSAR'\n",
    "\n",
    "reads_dir = './Mb_reads'\n",
    "ref_dir = './Mb_refs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1: multi-assembly with SPAdes\n",
    "\n",
    "Read naming convention: prefix_R1.fastq.gz (forward) and prefix_R2.fastq.gz (reverse)\n",
    "\n",
    "**read_to_process**: list of read prefixes, indicating which reads you would like assembled.\n",
    "\n",
    "**best_metric**: metric by which to select best assembly. Current options are any of the columns in the QUAST output, such as 'Largest contig', '# contigs', 'Total length', 'N50', 'N75', 'L50', and 'L75'.\n",
    "\n",
    "**max_v_min**: determines if best assembly is selected via max or min value of best_metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Best Assemblies (x12)\n",
    "reads_to_process = ['3A2', '4A3', '4A5', '4G3', 'CL1', 'CL2', 'PNG']\n",
    "best_metric = 'Longest contig'\n",
    "max_v_min = 'max'\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "print('=== Start! ===')\n",
    "\n",
    "for x in reads_to_process:\n",
    "    print('Starting process with '+x+' reads')\n",
    "    if 'ref' in os.listdir('.'):\n",
    "        !rm -r ./ref\n",
    "    if 'temp_assemblies' in os.listdir('.'):\n",
    "        !rm -r ./temp_assemblies\n",
    "    !mkdir ./temp_assemblies\n",
    "\n",
    "    #Error correct reads\n",
    "    print('read error correction')\n",
    "    error_correct = SPAdes_dir +'/bin/spades.py -o ./reads_error_correct  --only-error-correction --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(error_correct, shell=True)\n",
    "\n",
    "    #Assemblies - Standard\n",
    "    print('assembling reads with 12x parameter sets - this will take a while')\n",
    "    a1 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a1 --only-assembler --careful -k 21,33,55 --pe1-1 ./reads_error_correct/corrected/'+x+'_R1.fastq.00.0_0.cor.fastq.gz --pe1-2 ./reads_error_correct/corrected/'+x+'_R2.fastq.00.0_0.cor.fastq.gz'\n",
    "    subprocess.call(a1, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a1'):\n",
    "        print('a1 assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a2 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a2 --only-assembler --careful -k 21,33,55,77 --pe1-1 ./reads_error_correct/corrected/'+x+'_R1.fastq.00.0_0.cor.fastq.gz --pe1-2 ./reads_error_correct/corrected/'+x+'_R2.fastq.00.0_0.cor.fastq.gz'\n",
    "    subprocess.call(a2, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a2'):\n",
    "        print('a2 assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a3 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a3 --only-assembler --careful -k 21,33,55,77,99 --pe1-1 ./reads_error_correct/corrected/'+x+'_R1.fastq.00.0_0.cor.fastq.gz --pe1-2 ./reads_error_correct/corrected/'+x+'_R2.fastq.00.0_0.cor.fastq.gz'\n",
    "    subprocess.call(a3, shell=True)   \n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a3'):\n",
    "        print('a3 assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a4 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a4 --only-assembler --careful -k 21,33,55,77,99,127 --pe1-1 ./reads_error_correct/corrected/'+x+'_R1.fastq.00.0_0.cor.fastq.gz --pe1-2 ./reads_error_correct/corrected/'+x+'_R2.fastq.00.0_0.cor.fastq.gz'\n",
    "    subprocess.call(a4, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a4'):\n",
    "        print('a4 assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    #Assemblies - Meta\n",
    "    a1 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a1m --only-assembler --meta -k 21,33,55 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a1, shell=True)   \n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a1m'):\n",
    "        print('a1m assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a2 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a2m --only-assembler --meta -k 21,33,55,77 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a2, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a2m'):\n",
    "        print('a2m assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a3 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a3m --only-assembler --meta -k 21,33,55,77,99 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a3, shell=True) \n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a3m'):\n",
    "        print('a3m assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a4 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a4m --only-assembler --meta -k 21,33,55,77,99,127 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a4, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a4m'):\n",
    "        print('a4m assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    #Assemblies - Isolate\n",
    "    a1 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a1i --only-assembler --isolate -k 21,33,55 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a1, shell=True)  \n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a1i'):\n",
    "        print('a1i assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a2 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a2i --only-assembler --isolate -k 21,33,55,77 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a2, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a2i'):\n",
    "        print('a2i assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a3 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a3i --only-assembler --isolate -k 21,33,55,77,99 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a3, shell=True)  \n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a3i'):\n",
    "        print('a3i assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "    \n",
    "    a4 = SPAdes_dir + '/bin/spades.py -o ./temp_assemblies/a4i --only-assembler --isolate -k 21,33,55,77,99,127 --pe1-1 ' + reads_dir + '/'+x+'_R1.fastq.gz --pe1-2 ' + reads_dir + '/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(a4, shell=True)\n",
    "    if 'contigs.fasta' not in os.listdir('./temp_assemblies/a4i'):\n",
    "        print('a4i assembly failed; moving to next set of reads')\n",
    "        continue\n",
    "\n",
    "    #Annotate all assemblies with Prokka (may need to change contig names)\n",
    "    print('annotating all assemblies with prokka')\n",
    "    anno = ''\n",
    "    for y in ['a1','a2','a3','a4','a1m','a2m','a3m','a4m','a1i','a2i','a3i','a4i']:\n",
    "        anno = anno + 'prokka --outdir ./temp_assemblies/prokka_'+y+' --centre X --compliant --cpus 0 --prefix '+y+' ./temp_assemblies/'+y+'/contigs.fasta ; '\n",
    "    subprocess.call(anno, shell=True)\n",
    "    \n",
    "    #Count genes and compare all assemblies\n",
    "    print('counting ORFs in all assemblies')\n",
    "    count = ''\n",
    "    for y in ['a1','a2','a3','a4','a1m','a2m','a3m','a4m','a1i','a2i','a3i','a4i']:\n",
    "        count = count + './count_cds_partials.pl ./temp_assemblies/prokka_'+y+'/'+y+'.ffn >> ./temp_assemblies/counts.txt ; '\n",
    "    subprocess.call(count, shell=True)\n",
    "    \n",
    "    #Check lengths, number of contigs\n",
    "    print('checking assembly lengths, number of contigs')\n",
    "    quast = quast_dir + '/quast.py -o ./temp_assemblies/quast_output ./temp_assemblies/a*/contigs.fasta'\n",
    "    subprocess.call(quast, shell=True)\n",
    "    \n",
    "    #Check coverage of a2\n",
    "    print('checking coverage to determine if suitable for submitting to celera')\n",
    "    f = open(\"./temp_assemblies/coverage.txt\", \"w\")\n",
    "    cov = bbmap_dir + '/bbmap.sh in1=./reads_error_correct/corrected/'+x+'_R1.fastq.00.0_0.cor.fastq.gz in2=./reads_error_correct/corrected/'+x+'_R2.fastq.00.0_0.cor.fastq.gz ref=./temp_assemblies/a2/contigs.fasta covstats=./temp_assemblies/covstats.txt'\n",
    "    subprocess.call(cov, shell=True, stderr=f)\n",
    "    \n",
    "    #Compile coverage data, so it is all in one place\n",
    "    print('adding coverage data to masterfile')\n",
    "    t = open(\"./temp_assemblies/coverage.txt\", \"r\")\n",
    "    for line in t:\n",
    "        if 'Average coverage:' in line:\n",
    "            av_cov = line\n",
    "            av_cov = float(av_cov.split('\\t')[1].split('\\n')[0])\n",
    "            print('average coverage for '+x+' is '+str(av_cov))\n",
    "    with open(\"./assembly_database/assemblies_cov.txt\", \"a+\") as file:\n",
    "        file.seek(0)\n",
    "        data = file.read(100)\n",
    "        if len(data) > 0 :\n",
    "            file.write(\"\\n\")\n",
    "        file.write('average coverage for '+x+' is '+str(av_cov))\n",
    "\n",
    "    #Move all data generated to assembly_database, to document\n",
    "    print('compiling results')\n",
    "    mkdir_x = 'mkdir ./assembly_database/'+x+'_data'\n",
    "    subprocess.call(mkdir_x, shell=True)\n",
    "    cp_cov = 'cp ./temp_assemblies/coverage.txt ./assembly_database/'+x+'_data/'+x+'_coverage.txt'\n",
    "    subprocess.call(cp_cov, shell=True)\n",
    "    cp_counts = 'cp ./temp_assemblies/counts.txt ./assembly_database/'+x+'_data/'+x+'_orf-counts.txt'\n",
    "    subprocess.call(cp_counts, shell=True)\n",
    "    cp_quast = 'cp ./temp_assemblies/quast_output/report.tsv ./assembly_database/'+x+'_data/'+x+'_quast-report.tsv'\n",
    "    subprocess.call(cp_quast, shell=True)\n",
    "    \n",
    "    #Move best assembly to 'best assembly' dir\n",
    "    print('preserving assembly with the longest contig')\n",
    "    quast = pd.read_csv('./assembly_database/'+x+'_data/'+x+'_quast-report.tsv', sep='\\t', header=0)\n",
    "    quast.index = quast['Assembly']\n",
    "    quast.drop('Assembly', axis=1, inplace=True)\n",
    "    if max_v_min == 'max':\n",
    "        ba = quast.T[best_metric].idxmax()\n",
    "    elif max_v_min == 'min':\n",
    "        ba = quast.T[best_metric].idxmin()\n",
    "    ba = ba.split('_')[0]\n",
    "    best_assembly = './temp_assemblies/'+ba+'/contigs.fasta'\n",
    "    mv_script = 'cp '+best_assembly+' ./best_assemblies/'+x+'_'+ba+'_contigs.fasta'\n",
    "    subprocess.call(mv_script, shell=True)\n",
    "    \n",
    "    #Delete rest of assemblies\n",
    "    print('cleaning up before next round')\n",
    "    !rm -r ./ref\n",
    "    !rm -r ./temp_assemblies\n",
    "    !rm -r ./reads_error_correct\n",
    "\n",
    "print('=== Complete! ===')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: iterative scaffolding and gapfilling, for improved contiguity\n",
    "\n",
    "Prior to starting module 2, all assemblies need library files, stored in the SSPACE/GapFiller dir (see SSPACE and/or GapFiller documentation)\n",
    "\n",
    "The expected naming convention for library files is libraries_**SamplePrefix**_F_updatedIS.txt\n",
    "\n",
    "**assemblies_to_iT**: list of assembly prefixes to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assemblies_to_iT = ['4G3']\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "for sample in assemblies_to_iT:\n",
    "    print('Now starting with '+ sample)\n",
    "    refs_to_record =  glob.glob(ref_dir + '*')\n",
    "    print('Refs:')\n",
    "    print(refs_to_record)\n",
    "    ref_contigs =  glob.glob(ref_dir + '*' + sample + '_*')\n",
    "    if ref_contigs == 1:\n",
    "        print('There is already a reference genome for this sample code. Let\\'s see if we can improve on it...')\n",
    "        clean_refs = 'rm ' + ref_dir + ref_contigs[0].split('/')[-1]\n",
    "        print(clean_refs)\n",
    "        subprocess.call(clean_refs, shell=True)\n",
    "        contig_path = './iT_assemblies/' + ref_contigs[0].split('/')[-1]\n",
    "        print('contigs: ' + contig_path)    \n",
    "    else:\n",
    "        print('No reference genomes yet for this sample code.')\n",
    "        assemblies_path = \"./best_assemblies/\"\n",
    "        sample_contigs = glob.glob(assemblies_path+'*' + sample + '_*')\n",
    "        if len(sample_contigs) == 1:\n",
    "            contig_path = sample_contigs[0]\n",
    "            print('contigs: ' + contig_path)\n",
    "        else:\n",
    "            print('Could not find contigs for the sample')\n",
    "            continue\n",
    "        \n",
    "    prefix = sample\n",
    "    print('prefix: ' + prefix)\n",
    "    library_list = glob.glob(SSPACE_GF_dir + '/*_' + sample + '_F_updatedIS.txt')\n",
    "    if len(library_list) == 1:\n",
    "        library = '.' + library_list[0]\n",
    "        print('library_path: ' + library)\n",
    "    else:\n",
    "        print('Could not find library for the sample')\n",
    "        continue\n",
    "        \n",
    "    prog_doc = sample + '_iT_prog.csv'\n",
    "    print('name of progress doc: ' + prog_doc)\n",
    "    \n",
    "\n",
    "\n",
    "    with open(prog_doc, 'wb') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "    it_contigs = []\n",
    "\n",
    "    process_start_time = time.time()\n",
    "\n",
    "    for i in range(0,20):\n",
    "        print('Start of Iteration '+str(i))\n",
    "        print('==========================================================')\n",
    "        iteration_start_time = time.time()\n",
    "        if i == 0:\n",
    "            print('Counting contigs, to see where we are starting')\n",
    "            with open(contig_path,'r') as f:\n",
    "\n",
    "                file = [l.replace('\\n','') for l in f]\n",
    "\n",
    "            scaffs=0\n",
    "            for line in file:\n",
    "                if line.startswith(\">\"):\n",
    "                    scaffs += 1\n",
    "            print('Starting with '+str(scaffs)+' contigs')\n",
    "            fields=[i,scaffs]\n",
    "            with open(prog_doc, 'a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['sample', sample])\n",
    "                writer.writerow(['refs', refs_to_record])\n",
    "                writer.writerow(['contigs', contig_path])\n",
    "                writer.writerow(['library_path', library])\n",
    "                writer.writerow(fields)\n",
    "            \n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "            print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "            continue\n",
    "        print('Iteration '+str(i)+': SSPACE starting')\n",
    "        T0 = 'cd '+ SSPACE_GF_dir +' ; '\n",
    "        if i == 1:\n",
    "            SS = './SSPACE_Standard_v3.0.pl -l '+library+' -s .'+contig_path+' -x 1 -o 10 -r 0.75 -b '+prefix+'_sspace_'+str(i)+' -T 12 ; '\n",
    "            print('using original contigs')\n",
    "        else:\n",
    "            SS = './SSPACE_Standard_v3.0.pl -l '+library+' -s ../alt_fasta.fasta -x 1 -o 10 -r 0.75 -b '+prefix+'_sspace_'+str(i)+' -T 12 ; '\n",
    "            print('using alt_fasta')\n",
    "        run_1 = T0+SS\n",
    "        print(run_1)\n",
    "        subprocess.call(run_1, shell=True)\n",
    "        print('Iteration '+str(i)+': SSPACE completed')\n",
    "        print('iteration time elapsed = '+ str(round((time.time()-iteration_start_time)/60,2))+ ' mins')\n",
    "        print('process time elapsed = '+ str(round((time.time()-process_start_time)/60/60,2))+ ' hours')\n",
    "        print('==========================================================')\n",
    "        \n",
    "        print('Iteration '+str(i)+': Multi-CSAR starting')\n",
    "        MC = MultiCSAR_dir + '/multi-csar.php -t SSPACE_and_GapFiller/'+prefix+'_sspace_'+str(i)+'/'+prefix+'_sspace_'+str(i)+'.final.scaffolds.fasta -r Mb_refs --nuc -o '+prefix+'_multi-csar_'+str(i)+' ;'\n",
    "        run_2 = MC\n",
    "        print(run_2)\n",
    "        subprocess.call(run_2, shell=True)\n",
    "        print('Iteration '+str(i)+': Multi_CSAR completed')\n",
    "        print('iteration time elapsed = '+ str(round((time.time()-iteration_start_time)/60,2))+ ' mins')\n",
    "        print('process time elapsed = '+ str(round((time.time()-process_start_time)/60/60,2))+ ' hours')\n",
    "        print('==========================================================')\n",
    "    \n",
    "        shutil.rmtree(SSPACE_GF_dir + '/'+prefix+'_sspace_'+str(i), ignore_errors=True)\n",
    "        print('*Removed SSPACE file, keeping things tidy!!')\n",
    "        print('==========================================================')\n",
    "        \n",
    "        print('Iteration '+str(i)+': GapFiller starting')\n",
    "        T2 = 'cd SSPACE_and_GapFiller ; '\n",
    "        GF = './GapFiller.pl -l '+library+' -s ../'+prefix+'_multi-csar_'+str(i)+'/multi-csar.nuc.out.fna -b '+prefix+'_gapfilled_'+str(i)+' -T 12 -i 1000000 ;'\n",
    "        run_3 = T2+GF\n",
    "        print(run_3)\n",
    "        subprocess.call(run_3, shell=True)\n",
    "        print('Iteration '+str(i)+': GapFiller completed')\n",
    "        print('iteration time elapsed = '+ str(round((time.time()-iteration_start_time)/60,2))+ ' mins')\n",
    "        print('process time elapsed = '+ str(round((time.time()-process_start_time)/60/60,2))+ ' hours')\n",
    "        print('==========================================================')\n",
    "    \n",
    "        shutil.rmtree('./'+prefix+'_multi-csar_'+str(i), ignore_errors=True)\n",
    "        print('*Removed Multi-CSAR file, keeping things tidy!!')\n",
    "        print('==========================================================')\n",
    "\n",
    "        print('Iteration '+str(i)+': ScaffoldChopper starting')\n",
    "        alt_fasta=[]\n",
    "        with open('SSPACE_and_GapFiller/'+prefix+'_gapfilled_'+str(i)+'/'+prefix+'_gapfilled_'+str(i)+'.gapfilled.final.fa','r') as f:\n",
    "\n",
    "            file = [l.replace('\\n','') for l in f]\n",
    "\n",
    "        seq=[]\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                alt_fasta.append(line)\n",
    "                last_scaf = line\n",
    "                scaf_num = 0\n",
    "            elif 'N' in line:\n",
    "                if line.count('N') > 0:\n",
    "                    new_scafs = line.replace('N',\" \").split()\n",
    "                    for x in range(len(new_scafs)):\n",
    "                        if scaf_num == 0:\n",
    "                            scaf_num = scaf_num + 1\n",
    "                            alt_fasta.append(new_scafs[x])\n",
    "                        else:\n",
    "                            alt_fasta.append(last_scaf+'-'+str(scaf_num))\n",
    "                            scaf_num = scaf_num + 1\n",
    "                            alt_fasta.append(new_scafs[x])\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    alt_fasta.append(line)\n",
    "            else:\n",
    "                alt_fasta.append(line)\n",
    "        \n",
    "        \n",
    "    \n",
    "        with open('alt_fasta.fasta', 'w') as filehandle:\n",
    "            filehandle.writelines(\"%s\\n\" % line for line in alt_fasta)\n",
    "        \n",
    "\n",
    "        with open('alt_fasta.fasta','r') as f:\n",
    "\n",
    "            file = [l.replace('\\n','') for l in f]\n",
    "\n",
    "        scaffs=0\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                scaffs += 1\n",
    "            \n",
    "            \n",
    "        print('Iteration '+str(i)+': Gaps removed to make all scaffolds contiguous')\n",
    "        if i == 1:\n",
    "            save1 = 'cp ./alt_fasta.fasta ./iT_assemblies/iT_' + sample + '_' + str(i) + '_' + str(scaffs) + '.fasta'\n",
    "            subprocess.call(save1, shell=True)\n",
    "            print('Iteration 1 saved for future reference')\n",
    "        print('Iteration '+str(i)+' done!')\n",
    "        print('iteration time elapsed = '+ str(round((time.time()-iteration_start_time)/60,2))+ ' mins')\n",
    "        print('process time elapsed = '+ str(round((time.time()-process_start_time)/60/60,2))+ ' hours')\n",
    "        print('==========================================================')\n",
    "    \n",
    "        shutil.rmtree(SSPACE_GF_dir + '/'+prefix+'_gapfilled_'+str(i), ignore_errors=True)\n",
    "        print('*Removed GapFiller file, keeping things tidy!!')\n",
    "        print('==========================================================')\n",
    "    \n",
    "        print('There are still '+str(scaffs)+' contigs after '+str(i)+' iterations')\n",
    "        it_contigs.append([i,scaffs])\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "       \n",
    "        fields=[i,scaffs]\n",
    "        with open(prog_doc, 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(fields)\n",
    "        \n",
    "        if i > 15:    \n",
    "            df=pd.read_csv(prog_doc, header=None)\n",
    "            if (int(df[1].iloc[-11]) - int(df[1].iloc[-1]))/10 < 1:\n",
    "                break\n",
    "            else:\n",
    "                print('Still decreasing the number of contigs')\n",
    "    print('Just finished. Contigs were no longer decreasing.')\n",
    "    save = 'mv ./alt_fasta.fasta ./iT_assemblies/iT_' + sample + '_' + str(i) + '_' + str(scaffs) + '.fasta'\n",
    "    subprocess.call(save, shell=True)\n",
    "    move_prog = 'mv ./' + prog_doc + ' ./iT_progs/' + sample + '_' + str(i) + '_' + str(scaffs) + '_iT_prog.csv'\n",
    "    subprocess.call(move_prog, shell=True)\n",
    "    #to_refs = 'cp ./iT_assemblies/iT_' + sample + '_' + str(i) + '_' + str(scaffs) + '.fasta ./Mb_refs/iT_' + sample + '_' + str(i) + '_' + str(scaffs) + '.fasta'\n",
    "    #subprocess.call(to_refs, shell=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Celera/WGS, for better assemblies with sufficient coverage\n",
    "### Still under development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit eligible reads to celera/WGS\n",
    "reads_to_process = ['3A2']\n",
    "\n",
    "for x in reads_to_process:\n",
    "    print('Starting celera process with '+x+' reads')\n",
    "\n",
    "    #Error correct reads\n",
    "    print('read error correction')\n",
    "    error_correct = './SPAdes-3.14.0-Linux/bin/spades.py -o ./reads_error_correct-'+x+'  --only-error-correction --pe1-1 ./Mb_reads/'+x+'_R1.fastq.gz --pe1-2 ./Mb_reads/'+x+'_R2.fastq.gz'\n",
    "    subprocess.call(error_correct, shell=True)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./wgs-8.3rc2/Linux-amd64/bin/fastqToCA -insertsize 215 76 -libraryname 3A2_rec_215_76 -technology illumina-long -type sanger -mates ./reads_error_correct-3A2/corrected/3A2_R1.fastq.00.0_0.cor.fastq.gz,./reads_error_correct-3A2/corrected/3A2_R2.fastq.00.0_0.cor.fastq.gz > 3A2_rec_215_76.frg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./wgs-8.3rc2/Linux-amd64/bin/runCA -d ./3A2_0rec -p 3A2_0rec -s ./3A2-0rec.spec.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./quast-5.0.2/quast.py ./3A2-1F/9-terminator/3A2-1F.ctg.fasta ./3A2_0rec/9-terminator/3A2_0rec.ctg.fasta ./best_assemblies/3A2_a3_contigs.fasta\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
